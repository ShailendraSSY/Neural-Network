{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation,MaxPooling2D,Dropout\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,LearningRateScheduler\n",
    "from keras import regularizers\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.regularizers import l2\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10514 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "train_path = 'cats-and-dogs/train'\n",
    "valid_path = 'cats-and-dogs/valid'\n",
    "test_path  = 'cats-and-dogs/test'\n",
    "save_path = \".\"\n",
    "train_gen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    channel_shift_range=10.,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(directory=train_path, target_size=(224,224),\n",
    "    classes=['dog', 'cat'], batch_size=32)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(directory=valid_path, target_size=(224,224), \n",
    "    classes=['dog', 'cat'], batch_size=32)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(directory=test_path, target_size=(224,224),\n",
    "    classes=['dog', 'cat'], batch_size=32,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 50.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Partially Trained Model\n",
      "Epoch 1/150\n",
      "329/329 [==============================] - 676s 2s/step - loss: 0.4766 - accuracy: 0.8207 - val_loss: 0.4236 - val_accuracy: 0.8581\n",
      "Epoch 2/150\n",
      "329/329 [==============================] - 650s 2s/step - loss: 0.4554 - accuracy: 0.8344 - val_loss: 0.4706 - val_accuracy: 0.8289\n",
      "Epoch 3/150\n",
      "329/329 [==============================] - 3555s 11s/step - loss: 0.4478 - accuracy: 0.8327 - val_loss: 0.4186 - val_accuracy: 0.8564\n",
      "Epoch 4/150\n",
      "329/329 [==============================] - 662s 2s/step - loss: 0.4378 - accuracy: 0.8414 - val_loss: 0.4099 - val_accuracy: 0.8621\n",
      "Epoch 5/150\n",
      "329/329 [==============================] - 1426s 4s/step - loss: 0.4227 - accuracy: 0.8484 - val_loss: 0.3893 - val_accuracy: 0.8734\n",
      "Epoch 6/150\n",
      "329/329 [==============================] - 2417s 7s/step - loss: 0.4087 - accuracy: 0.8549 - val_loss: 0.3807 - val_accuracy: 0.8729\n",
      "Epoch 7/150\n",
      "204/329 [=================>............] - ETA: 3:55 - loss: 0.4020 - accuracy: 0.8601"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3),kernel_initializer='glorot_uniform',\n",
    "           bias_initializer='zeros', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='glorot_uniform', \n",
    "           bias_initializer='zeros', kernel_regularizer=l2(0.0005)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='glorot_uniform',\n",
    "           bias_initializer='zeros', kernel_regularizer=l2(0.0005)),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='glorot_uniform', \n",
    "           bias_initializer='zeros', kernel_regularizer=l2(0.0005)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy',optimizer=SGD(lr=0.00001, decay=1e-6, momentum=0.9, nesterov=True),metrics=['accuracy'])\n",
    "\n",
    "# Add all the call backs for Keras\n",
    "reduce_lr_loss = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "\tfactor=0.1, \n",
    "    patience=7, \n",
    "\tverbose=1, \n",
    "    min_delta=1e-4,\n",
    "\tmode='auto')\n",
    "\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "\tpatience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "mcp_save       = ModelCheckpoint(\n",
    "    'cat_dog_kaggle.h5', \n",
    "\tsave_best_only=True, \n",
    "\tmonitor='val_loss', \n",
    "\tmode='auto'\n",
    ")\n",
    "\n",
    "\n",
    "if os.path.isfile('cat_dog_kaggle.h5'):\n",
    "        #This code is implemented to load the partly trained model which was stopped due to some reason\n",
    "    print(\"Running the Partially Trained Model\")\n",
    "    partially_trained_model = load_model('cat_dog_kaggle.h5')\n",
    "    history = partially_trained_model.fit_generator(generator=train_batches, steps_per_epoch=len(train_batches), \n",
    "                              validation_data=valid_batches, validation_steps=len(valid_batches), \n",
    "                              epochs=150, callbacks=[earlyStopping, reduce_lr_loss,mcp_save],verbose=1) \n",
    "else:\n",
    "    print(\"Running the Training of Model from Scratch\")\n",
    "    history = model.fit_generator(generator=train_batches, steps_per_epoch=len(train_batches), \n",
    "                              validation_data=valid_batches, validation_steps=len(valid_batches), \n",
    "                              epochs=150, callbacks=[earlyStopping, reduce_lr_loss,mcp_save],verbose=1)\n",
    "\n",
    "\n",
    "model.save(os.path.join(save_path,\"cat_dog_kaggle_final.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_batches, steps_per_epoch=len(train_batches), \n",
    "                              validation_data=valid_batches, validation_steps=len(valid_batches), \n",
    "                              epochs=5, callbacks=[reduce_lr_loss],verbose=1) \n",
    "acc = history.history['accuracy'] \n",
    "val_acc = history.history['val_accuracy'] \n",
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.legend() \n",
    "plt.figure() \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
    "plt.title('Training and validation loss') \n",
    "plt.savefig('accuracy.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plots images with labels within jupyter notebook\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)/rows\n",
    "    #cols = 8\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "#test_imgs, labels = next(test_batches)\n",
    "#plots(test_batches, figsize=(100,80), rows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator=test_batches, steps=len(test_batches), verbose=0)\n",
    "pred_label = np.argmax(predictions,axis=1)\n",
    "classes = np.argmax(predictions, axis=1)\n",
    "cm = confusion_matrix(test_batches.labels,pred_label)\n",
    "f,ax = plt.subplots(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "accuracy = (tn + tp)/(tn + tp + fn +fp)\n",
    "precision = precision_score(test_batches.labels, pred_label, average='binary')\n",
    "recall = recall_score(test_batches.labels, pred_label,average='binary')\n",
    "f1_score = f1_score(test_batches.labels, pred_label, average='binary')\n",
    "score = metrics.accuracy_score(test_batches.labels, pred_label)\n",
    "log_score = metrics.log_loss(pred_label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Precision \",precision*100)\n",
    "print(\"Recall \",recall*100)\n",
    "print(\"F1 Score \",recall*100)\n",
    "print(\"Accuracy of the model\",accuracy*100)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "print(\"Log loss score: {}\".format(log_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "plot_roc(pred_label,test_batches.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
