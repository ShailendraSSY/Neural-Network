{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Activation,MaxPooling2D,Dropout,Concatenate,Input,Add,GlobalAveragePooling2D,multiply\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping,LearningRateScheduler,CSVLogger,LambdaCallback,TensorBoard\n",
    "from keras import regularizers\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.regularizers import l2\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/'\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10514 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "train_path = 'cats-and-dogs/train'\n",
    "valid_path = 'cats-and-dogs/valid'\n",
    "test_path  = 'cats-and-dogs/test'\n",
    "save_path = \".\"\n",
    "train_gen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    channel_shift_range=10.,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(directory=train_path, target_size=(150,150),\n",
    "    classes=['dog', 'cat'], batch_size=16)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(directory=valid_path, target_size=(150,150), \n",
    "    classes=['dog', 'cat'], batch_size=16)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(directory=test_path, target_size=(150,150),\n",
    "    classes=['dog', 'cat'], batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_print_callback = LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: print(\"LearningRate of %e\",model.optimizer.lr))\n",
    "\n",
    "earlyStopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "\tpatience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr_loss = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "\tfactor=0.1, \n",
    "    patience=7, \n",
    "\tverbose=1, \n",
    "    min_delta=1e-4,\n",
    "\tmode='auto')\n",
    "\n",
    "mcp_save       = ModelCheckpoint(\n",
    "    'cat_dog_ckpt_densenet.h5', \n",
    "\tsave_best_only=True, \n",
    "\tmonitor='val_loss', \n",
    "\tmode='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block(in_block, ch, ratio=16):\n",
    "    x = GlobalAveragePooling2D()(in_block)\n",
    "    x = Dense(ch//ratio, activation='relu')(x)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return multiply([in_block, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_,num_kernel,growth_rate,kernel_size):\n",
    "\tbn   =  BatchNormalization()(input_)\n",
    "\tact  = Activation('relu')(bn)\n",
    "\tconv = Conv2D(num_kernel, (3,3), padding='same',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   bias_initializer='zeros', kernel_regularizer=l2(0.0005))(act)\n",
    "\tse = se_block(conv,num_kernel)\n",
    "\treturn se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a dense block which will connect a layer with all previous layer using concatenation,instead of add as in resnet'''\n",
    "def dense_block(num_dense_blk,x,nb_channels,growth_rate,kernel_size):\n",
    "    x_list = [x]\n",
    "    for i in range(num_dense_blk):\n",
    "        cb = conv_block(x,nb_channels, growth_rate,kernel_size)\n",
    "        x_list.append(cb)\n",
    "        x = Concatenate(axis=-1)(x_list)\n",
    "    nb_channels += growth_rate\n",
    "    return x, nb_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creates a transition layer between dense blocks as transition, which do convolution and pooling.\n",
    "    Transition block uses 1x1 conv2d for downsampling'''\n",
    "def transition_block(x, nb_channels,growth_rate):\n",
    "  \n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tx = Conv2D(nb_channels, (1, 1), padding='same',\n",
    "                      use_bias=False, kernel_regularizer=l2(0.0005))(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\tnb_channels = nb_channels + growth_rate\n",
    "\treturn x,nb_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def output_layer(x,num_kernel):\n",
    "\tx = BatchNormalization()(x)\n",
    "\tx = Activation('relu')(x)\n",
    "\tx = Conv2D(num_kernel, (3,3), padding='same',\n",
    "               kernel_initializer='glorot_uniform',\n",
    "               bias_initializer='zeros', kernel_regularizer=l2(0.0005))(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\tx = Dropout(0.5)(x)\n",
    "\tx = Flatten()(x)\n",
    "\tx = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_rate =16\n",
    "nb_channels = growth_rate * 2\n",
    "visible    = Input(shape=(150, 150, 3))\n",
    "kernel_size = [(3,3),(3,3),(3,3),(3,3)]\n",
    "num_layers_dense_blk = 3\n",
    "x = Conv2D(nb_channels, (3,3), padding='same',strides=(1,1),\n",
    "                      use_bias=False, kernel_regularizer=l2(0.0005))(visible)\n",
    "for i in range(4):\n",
    "    x, nb_channels = dense_block(num_layers_dense_blk,x,nb_channels,growth_rate,kernel_size[i])\n",
    "    x, nb_channels = transition_block(x, nb_channels,growth_rate)\n",
    "x = output_layer(x,nb_channels)\n",
    "model = Model(inputs=visible, outputs=x)\n",
    "\n",
    "model.save('densenet_experiment.h5')\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "276/658 [===========>..................] - ETA: 5:17 - loss: 1.7312 - accuracy: 0.5627"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit_generator(generator=train_batches, steps_per_epoch=len(train_batches), \n",
    "                              validation_data=valid_batches, validation_steps=len(valid_batches), \n",
    "                              epochs=200, callbacks=[reduce_lr_loss],verbose=1) \n",
    "acc = history.history['accuracy'] \n",
    "val_acc = history.history['val_accuracy'] \n",
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.legend() \n",
    "plt.figure() \n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
    "plt.title('Training and validation loss') \n",
    "plt.savefig('accuracy.png')\n",
    "plt.show()\n",
    "model.save('densenet_experiment.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator=test_batches, steps=len(test_batches), verbose=0)\n",
    "pred_label = np.argmax(predictions,axis=1)\n",
    "classes = np.argmax(predictions, axis=1)\n",
    "cm = confusion_matrix(test_batches.labels,pred_label)\n",
    "f,ax = plt.subplots(figsize=(4, 4))\n",
    "sns.heatmap(cm, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "print(classification_report(test_batches.classes, pred_label,\n",
    "\ttarget_names=test_batches.class_indices.keys()))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "accuracy = (tn + tp)/(tn + tp + fn +fp)\n",
    "precision = precision_score(test_batches.labels, pred_label, average='binary')\n",
    "recall = recall_score(test_batches.labels, pred_label,average='binary')\n",
    "f1_score = f1_score(test_batches.labels, pred_label, average='binary')\n",
    "score = metrics.accuracy_score(test_batches.labels, pred_label)\n",
    "log_score = metrics.log_loss(pred_label, predictions)\n",
    "print(\"Precision \",precision*100)\n",
    "print(\"Recall \",recall*100)\n",
    "print(\"F1 Score \",recall*100)\n",
    "print(\"Accuracy of the model\",accuracy*100)\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "print(\"Log loss score: {}\".format(log_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, _ = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "plot_roc(pred_label,test_batches.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
